{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View more python tutorial on my Youtube and Youku channel!!!\n",
    "\n",
    "# Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg\n",
    "# Youku video tutorial: http://i.youku.com/pythontutorial\n",
    "\n",
    "\"\"\"\n",
    "Please note, this code is only for python 3+. If you are using python 2+, please modify the code accordingly.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow as image_summary\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-93c6d828e070>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/hsuchaochun/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/hsuchaochun/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hsuchaochun/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hsuchaochun/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/hsuchaochun/anaconda3/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# number 1 to 10 data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "train_img, train_lab = mnist.train.images, mnist.train.labels\n",
    "test_img, test_lab = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "ITERATION = 5000\n",
    "OUTPUT_PATH_LOG = './test'\n",
    "L2_REGULARIZATION = False\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_accuracy(v_xs, v_ys):\n",
    "#     global prediction\n",
    "#     y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "#     correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))\n",
    "#     accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#     result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(layer, stimuli):\n",
    "    units = sess.run(layer, feed_dict={xs:np.reshape(stimuli, [1,784], order='F'), keep_prob:1.0})\n",
    "    plot_nn_filter(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nn_filter(units):\n",
    "    import math\n",
    "    filters = units.shape[3]\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    n_columns = 6\n",
    "    n_rows = math.ceil(filters / n_columns) + 1\n",
    "    for i in range(filters):\n",
    "        plt.subplot(n_rows, n_columns, i+1)\n",
    "        plt.title('Filter ' + str(i))\n",
    "        plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-65abd26944b4>:55: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "h_fc1_drop,  Tensor(\"fc1/dropout/mul_1:0\", shape=(?, 1024), dtype=float32)\n",
      "loss, Tensor(\"loss/Mean:0\", shape=(), dtype=float32)\n",
      "prediction,  Tensor(\"fc2/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "y_in,  Tensor(\"Placeholder_1:0\", shape=(?, 10), dtype=float32)\n",
      "result,  Tensor(\"Equal:0\", shape=(?,), dtype=bool)\n",
      "accuracy,  Tensor(\"Accuracy/Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x_in = tf.placeholder(dtype=tf.float32, shape=(None, 28*28))/255.\n",
    "y_in = tf.placeholder(dtype=tf.float32, shape=(None, 10))\n",
    "\n",
    "x_image = tf.reshape(x_in, [-1, 28, 28, 1])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# # 紀錄 3 張影像在 tensorboard 上\n",
    "# tf.summary.image('Input_images', x_image, max_outputs = 3)\n",
    "# # print(x_image.shape)  # [n_samples, 28,28,1]\n",
    "\n",
    "## conv1 layer ##\n",
    "with tf.name_scope('conv1'):\n",
    "    with tf.name_scope('weights'):\n",
    "        # patch 5x5, in size 1, out size 32\n",
    "        W_conv1 = weight_variable([5, 5, 1, 32], name='W_conv1')\n",
    "        tf.summary.histogram('conv1/weights', W_conv1)\n",
    "    with tf.name_scope('bias'):\n",
    "        b_conv1 = bias_variable([32], name='b_conv1')\n",
    "        tf.summary.histogram('conv1/biases', b_conv1)\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) +\n",
    "                         b_conv1)  # output size 28x28x32\n",
    "    tf.summary.histogram('conv1/outputs', h_conv1)\n",
    "    # output size 14x14x32\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "## conv2 layer ##\n",
    "with tf.name_scope('conv2'):\n",
    "    with tf.name_scope('weights'):\n",
    "        # patch 5x5, in size 32, out size 64\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64], name='W_conv2')\n",
    "        tf.summary.histogram('conv2/weights', W_conv2)\n",
    "    with tf.name_scope('bias'):\n",
    "        b_conv2 = bias_variable([64], name='b_conv2')\n",
    "        tf.summary.histogram('conv2/biases', b_conv2)\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) +\n",
    "                         b_conv2)  # output size 14x14x64\n",
    "    tf.summary.histogram('conv2/outputs', h_conv2)\n",
    "    # output size 7x7x64\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "## fc1 layer ##\n",
    "with tf.name_scope('fc1'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W_fc1 = weight_variable([7*7*64, 1024], name='W_fc1')\n",
    "        tf.summary.histogram('fc1/weights', W_fc1)\n",
    "    with tf.name_scope('bias'):\n",
    "        b_fc1 = bias_variable([1024], name='b_fc1')\n",
    "        tf.summary.histogram('fc1/biases', b_fc1)\n",
    "    # [n_samples, 7, 7, 64] ->> [n_samples, 7*7*64]\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    tf.summary.histogram('fc1/outputs', h_fc1)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## fc2 layer ##\n",
    "with tf.name_scope('fc2'):\n",
    "    with tf.name_scope('weights'):\n",
    "        W_fc2 = weight_variable([1024, 10], name='W_fc2')\n",
    "        tf.summary.histogram('fc2/weights', W_fc2)\n",
    "    with tf.name_scope('bias'):\n",
    "        b_fc2 = bias_variable([10], name='b_fc2')\n",
    "        tf.summary.histogram('fc2/biases', b_fc2)\n",
    "    prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "    tf.summary.histogram('fc2/outputs', prediction)\n",
    "print('h_fc1_drop, ', h_fc1_drop)\n",
    "    \n",
    "## Loss ##\n",
    "with tf.name_scope('loss'):\n",
    "    if L2_REGULARIZATION:\n",
    "        l2_loss = 0.005*tf.nn.l2_loss(W_conv1) + 0.005*tf.nn.l2_loss(W_conv2) + 0.005*tf.nn.l2_loss(W_fc1) + 0.005*tf.nn.l2_loss(W_fc2)\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(y_in * tf.log(prediction) + l2_loss,\n",
    "                                                reduction_indices=[1]))\n",
    "    else:\n",
    "        loss = tf.reduce_mean(-tf.reduce_sum(y_in * tf.log(prediction),\n",
    "                                                reduction_indices=[1]))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    print('loss,', loss)\n",
    "    \n",
    "## optimizer ##\n",
    "with tf.name_scope('Optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "print('prediction, ', prediction)\n",
    "print('y_in, ', y_in)\n",
    "result = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_in, 1))\n",
    "print('result, ', result)\n",
    "\n",
    "## accuracy ##\n",
    "with tf.name_scope('Accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(result, tf.float32))\n",
    "    print('accuracy, ', accuracy)\n",
    "    # 紀錄 accuracy\n",
    "    tf.summary.scalar('Accuracy', accuracy)\n",
    "    \n",
    "# 把上面所有的 tf.summary 整合成一個 operation call\n",
    "opsSummary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images=x_image[:25]\n",
    "# tf.summary.image('25 training data examples', images, max_outputs = 25)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#Creat writer to write data needed for tensorboard\n",
    "writer = tf.summary.FileWriter(OUTPUT_PATH_LOG, sess.graph)\n",
    "\n",
    "#Show graph of neural network in tensorboard\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "writerTrain = tf.summary.FileWriter(os.path.join(OUTPUT_PATH_LOG, 'train'))\n",
    "writerTest = tf.summary.FileWriter(os.path.join(OUTPUT_PATH_LOG, 'test'))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in tqdm_notebook(range(mnist.train.num_examples // BATCH_SIZE)):\n",
    "#     batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "#     print(np.size(batch[0]))\n",
    "#     print(batch[0])\n",
    "#     sess.run(optimizer, feed_dict = {x_in:batch[0], y_in:batch[1], keep_prob: 0.5})\n",
    "\n",
    "# sess.run(tf.print(x_in))    \n",
    "# sess.run(tf.print(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsuchaochun/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e659f5961fb49539994cee06180ab6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=550.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(EPOCH):\n",
    "    # mini batch training\n",
    "    for j in tqdm_notebook(range(mnist.train.num_examples // BATCH_SIZE)):\n",
    "        batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(optimizer, feed_dict = {x_in:batch[0], y_in:batch[1], keep_prob: 0.5})\n",
    "\n",
    "#     saver = tf.train.Saver()\n",
    "#     saver.save(sess, os.path.join(OUTPUT_PATH_LOG, 'model.ckpt'))\n",
    "    \n",
    "    print('QQQ')\n",
    "    train_accuracy = sess.run(accuracy, feed_dict = {x_in:train_img, y_in:train_lab})\n",
    "    test_accuracy = sess.run(accuracy, feed_dict = {x_in:test_img, y_in:test_lab})\n",
    "    print('QQQQQ')\n",
    "    \n",
    "    print('Epoch %2d: acc = %.3f, test_acc = %.3f' % (i+1, train_accuracy*100., test_accuracy*100.))\n",
    "    \n",
    "    # Calculate desired information to be shown in tensorboard\n",
    "    summary = sess.run(opsSummary, feed_dict = {x_in:train_img, y_in:train_lab})\n",
    "    writerTrain.add_summary(summary, global_step=i)\n",
    "    \n",
    "    summary = sess.run(opsSummary, feed_dict = {x_in:test_img, y_in:test_lab})\n",
    "    writerTest.add_summary(summary, global_step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
